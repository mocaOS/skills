# decc0 Web Interface Configuration
# Copy this file to .env and configure your LLM provider

# =============================================================================
# LLM PROVIDER SELECTION
# =============================================================================
# Choose one of: litellm, vllm, compute3, venice, openai, anthropic, ollama
LLM_PROVIDER=litellm

# =============================================================================
# LITELLM (Default - OpenAI-compatible proxy)
# Docs: https://docs.litellm.ai/docs/
# =============================================================================
LITELLM_BASE_URL=http://localhost:4000
LITELLM_API_KEY=your-litellm-api-key
LITELLM_MODEL=gpt-3.5-turbo

# =============================================================================
# vLLM (Self-hosted LLM inference)
# Docs: https://docs.vllm.ai/en/latest/
# =============================================================================
VLLM_BASE_URL=http://localhost:8000
VLLM_API_KEY=
VLLM_MODEL=meta-llama/Llama-2-7b-chat-hf

# =============================================================================
# COMPUTE3 (GPU cloud + LLM API)
# Docs: https://docs.compute3.ai/
# Get API key: https://console.compute3.ai
# =============================================================================
COMPUTE3_API_KEY=your-compute3-api-key
COMPUTE3_MODEL=deepseek-v3.1

# =============================================================================
# VENICE (Privacy-focused AI)
# Docs: https://docs.venice.ai/
# =============================================================================
VENICE_API_KEY=your-venice-api-key
VENICE_MODEL=llama-3.3-70b

# =============================================================================
# OPENAI
# Docs: https://platform.openai.com/docs/
# =============================================================================
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o-mini

# =============================================================================
# ANTHROPIC
# Docs: https://docs.anthropic.com/
# =============================================================================
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-haiku-20240307

# =============================================================================
# OLLAMA (Local LLM)
# Docs: https://ollama.ai/
# =============================================================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
PORT=3001
